{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91be04e6-dc33-402c-b84d-ad069b3d04b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6dbd30-4365-40e0-a46c-79e5c6f0b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9649695e-8ba6-41fa-915e-fc85566acc1a",
   "metadata": {},
   "source": [
    "# 1.3 Retrieval and Search - Notes\n",
    "- Before jumping into using elasticsearch to index our documents, we're going to use the search engine build by DTC\n",
    "- In order to do that, I need to import minsearch.py (the search engine library)\n",
    "- Once that's done, we need to understand a few things about how `minsearch` is implemented:\n",
    "    - `minsearch.Index()` is the method used to index a document and takes a few parameters: `text_fields` and `keyword_fields`\n",
    "        - text_fields: the fields we use to search\n",
    "        - keyword_fields: the fields used to group the data (i.e. similar to a WHERE clause in SQL)\n",
    "    - So for example, if you pass a query like: ***\"How do I execute a command in a running docker container?\"*** the search engine would filter results by `keyword_fields` and would search through `text_fields`\n",
    "    - index.fit() is the method used to specify the document you want to *fit* your Index to. So in this case, you would pass it the document containing all the data with the relevant keyword_fields and text_fields\n",
    "    - index.search():\n",
    "        - This is the method used to actually search the fitted document for the specific question\n",
    "        - All the `text_fields` you search through are given equal weighting. If you want to change that, you can use a parameter called `boost` which allows you to ***relatively*** overweight or underweight certain `text_fields` by passing it a dictionary with `{text_field: weight}`\n",
    "        - There are two other parameters, that are pretty straightforward: `filter_dict` which just lets you filter based on a `keyword_fields` again as a dict of the form `{\"keyword_fields\": \"value\"}` entry and `num_results` which just limits the number of elements it returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d7492ed-677b-4288-bbe1-2ca1dc925f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the relative path in order to import minsearch.py\n",
    "current_dir = os.getcwd()\n",
    "intro_dir = os.path.abspath(os.path.join(current_dir, \"../../../01-intro\"))\n",
    "sys.path.append(intro_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7711776d-d8e4-47fc-9d97-a0dd757b2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd9b7c5-b824-4426-b0df-6f4113ce2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the FAQ documents (already parsed into json) into a list called documents\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4f7291-a700-46b5-bd02-ef0bb672b8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Field names: ['question', 'text', 'section', 'course']\n",
      "\n",
      "courses:\n",
      " machine-learning-zoomcamp\n",
      "mlops-zoomcamp\n",
      "data-engineering-zoomcamp\n"
     ]
    }
   ],
   "source": [
    "field_names = {key for document in documents for key in document.keys()}\n",
    "print(\"\\nField names:\", list(field_names));\n",
    "print(\"\\ncourses:\\n\",'\\n'.join({course['course'] for course in documents_raw}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e8b208-1ee2-4304-b3c6-fef5b45da36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index based on the fields in our FAQ document\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbc06440-7adf-4505-b627-7347ca563416",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do I execute a command in a running docker container?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4363bacf-96c8-4cc0-a5f7-30b7cce31b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x76f0fdc59e40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9161d828-1332-4e94-b26f-f58bb36dce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = {\n",
    "    \"question\":3,\n",
    "    \"text\":1,\n",
    "    \"section\":0.5\n",
    "}\n",
    "\n",
    "results = index.search(\n",
    "    query = question,\n",
    "    filter_dict = {\"course\":\"data-engineering-zoomcamp\"},\n",
    "    boost_dict = boost,\n",
    "    num_results = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf43f0c9-e23d-420f-8ead-28bb76863c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'In case running pgcli  locally causes issues or you do not want to install it locally you can use it running in a Docker container instead.\\nBelow the usage with values used in the videos of the course for:\\nnetwork name (docker network)\\npostgres related variables for pgcli\\nHostname\\nUsername\\nPort\\nDatabase name\\n$ docker run -it --rm --network pg-network ai2ys/dockerized-pgcli:4.0.1\\n175dd47cda07:/# pgcli -h pg-database -U root -p 5432 -d ny_taxi\\nPassword for root:\\nServer: PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1)\\nVersion: 4.0.1\\nHome: http://pgcli.com\\nroot@pg-database:ny_taxi> \\\\dt\\n+--------+------------------+-------+-------+\\n| Schema | Name             | Type  | Owner |\\n|--------+------------------+-------+-------|\\n| public | yellow_taxi_data | table | root  |\\n+--------+------------------+-------+-------+\\nSELECT 1\\nTime: 0.009s\\nroot@pg-database:ny_taxi>',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': 'PGCLI - running in a Docker container',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Sometimes, when you try to restart a docker image configured with a network name, the above message appears. In this case, use the following command with the appropriate container name:\\n>>> If the container is running state, use docker stop <container_name>\\n>>> then, docker rm pg-database\\nOr use docker start instead of docker run in order to restart the docker image without removing it.',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': 'Docker - Error response from daemon: Conflict. The container name \"pg-database\" is already in use by container “xxx”.  You have to remove (or rename) that container to be able to reuse that name.',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"You may have this error:\\nRetrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.u\\nrllib3.connection.HTTPSConnection object at 0x7efe331cf790>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')':\\n/simple/pandas/\\nPossible solution might be:\\n$ winpty docker run -it --dns=8.8.8.8 --entrypoint=bash python:3.9\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': 'Docker - Cannot pip install on Docker container (Windows)',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c6171-1c68-458c-b72e-d448f3046c99",
   "metadata": {},
   "source": [
    "# 1.4 Generating Answers with OpenAI GPT 4.0\n",
    "- In this section, we'll be packaging up the response from our basic search engine in 1.3 and passing it as part of the context to the OpenAI API\n",
    "- Using the completions API is pretty straightforward for basic usage. The documentation for the compeletions API can be found here: https://platform.openai.com/docs/api-reference/chat/create\n",
    "- The general structure of this section is as follows:\n",
    "    - Assume a set of results are generated based on the minsearch (or any search engine) in the previous section\n",
    "    - We want to build a context that includes instructions to the LLM to restrict its answers to content from the results above *AND* the relevant content from those results for it to analyze\n",
    "    - We pass that context as a prompt to the LLM and get results back\n",
    "    - That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d385a3a-d900-4a29-aaa9-37027b47d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad4185bd-5bab-42b6-b416-3330566e5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e30eae7a-4310-4240-8997-8202b875f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a teaching assistant for a bootcamp course.\n",
    "Restrict your answers to the QUESTION to the content in CONTEXT only.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: {context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e65796e-e630-4bb9-af16-d2cc73cf652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "\n",
    "for doc in results:\n",
    "    context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f2f27e6-ebc3-4cdf-8aff-bcf4727c40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question=question, context=context).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f617219-33fe-4e69-8fdb-de33d684179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a teaching assistant for a bootcamp course.\n",
      "Restrict your answers to the QUESTION to the content in CONTEXT only.\n",
      "\n",
      "QUESTION: How do I execute a command in a running docker container?\n",
      "\n",
      "CONTEXT: section: Module 1: Docker and Terraform\n",
      "question: PGCLI - running in a Docker container\n",
      "answer: In case running pgcli  locally causes issues or you do not want to install it locally you can use it running in a Docker container instead.\n",
      "Below the usage with values used in the videos of the course for:\n",
      "network name (docker network)\n",
      "postgres related variables for pgcli\n",
      "Hostname\n",
      "Username\n",
      "Port\n",
      "Database name\n",
      "$ docker run -it --rm --network pg-network ai2ys/dockerized-pgcli:4.0.1\n",
      "175dd47cda07:/# pgcli -h pg-database -U root -p 5432 -d ny_taxi\n",
      "Password for root:\n",
      "Server: PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1)\n",
      "Version: 4.0.1\n",
      "Home: http://pgcli.com\n",
      "root@pg-database:ny_taxi> \\dt\n",
      "+--------+------------------+-------+-------+\n",
      "| Schema | Name             | Type  | Owner |\n",
      "|--------+------------------+-------+-------|\n",
      "| public | yellow_taxi_data | table | root  |\n",
      "+--------+------------------+-------+-------+\n",
      "SELECT 1\n",
      "Time: 0.009s\n",
      "root@pg-database:ny_taxi>\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - Error response from daemon: Conflict. The container name \"pg-database\" is already in use by container “xxx”.  You have to remove (or rename) that container to be able to reuse that name.\n",
      "answer: Sometimes, when you try to restart a docker image configured with a network name, the above message appears. In this case, use the following command with the appropriate container name:\n",
      ">>> If the container is running state, use docker stop <container_name>\n",
      ">>> then, docker rm pg-database\n",
      "Or use docker start instead of docker run in order to restart the docker image without removing it.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - Cannot pip install on Docker container (Windows)\n",
      "answer: You may have this error:\n",
      "Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.u\n",
      "rllib3.connection.HTTPSConnection object at 0x7efe331cf790>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')':\n",
      "/simple/pandas/\n",
      "Possible solution might be:\n",
      "$ winpty docker run -it --dns=8.8.8.8 --entrypoint=bash python:3.9\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "944bd3c5-c2fe-4a80-8ada-a7a6be1c2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o\",\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7e669b5-2cf2-4f8c-b7df-f0299996b5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To execute a command in a running Docker container, you can follow these steps:\n",
      "\n",
      "1. **Start a Bash session** in the running container by using the `docker exec` command. For example, if your container name is `pg-database`, you can use:\n",
      "   ```sh\n",
      "   docker exec -it pg-database bash\n",
      "   ```\n",
      "\n",
      "2. **Run the command** you need once you are inside the container. \n",
      "\n",
      "For example, if you want to run `pgcli` on a running Docker container:\n",
      "```sh\n",
      "docker exec -it pg-database pgcli -h pg-database -U root -p 5432 -d ny_taxi\n",
      "```\n",
      "This command starts a `pgcli` session directly in the running `pg-database` container with the specified host, user, port, and database information.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
