{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Zoomcamp - Week 7 Notes\n",
    "\n",
    "- In this section, we walk through a full example project\n",
    "- I think what I'll do is follow along with the lectures, but re-orient it to my own dataset\n",
    "- Some project ideas:\n",
    "  - An annotation system that takes nature based valuation academic papers and extracts content and maps that content to a fixed data model\n",
    "  - A Q&A system using a company's history of support requests and creates a support agent to assist with issue management\n",
    "  - A system that automatically updates nutrition macro tracking based on just on photos of the food you're eating\n",
    "    - For a project like this, why would a knowledge base be useful? The only reason to have a knowledge base is to perhaps store common recips from which the food in the photographed image might have come from\n",
    "    - This is the project I'm going with despite there being a lot of apps that already do this :(\n",
    "    - What shall I call it?\n",
    "      - MacroMinder.AI\n",
    "- One important consideration is that I'll be working through the set up in these notes, but the final project will actually be in a separate Github repo\n",
    "  - The link to the that repo is [here](INSERT LINK TO REPO)\n",
    "\n",
    "## Project Criteria\n",
    "- So as a reminder, for this LLM application to be \"fully functional\" it needs to satisfy the following conditions:\n",
    "  * Select a dataset that you're interested in\n",
    "  * Ingest the data into a knowledge base\n",
    "  * Implement the RAG flow: query the knowledge base, build the prompt, send the promt to an LLM\n",
    "  * Evaluate the performance of your RAG flow\n",
    "  * Create an interface for the application\n",
    "  * Collect user feedback and monitor your application\n",
    "- And the evaluation details are below:\n",
    "  * Problem description\n",
    "      * 0 points: The problem is not described\n",
    "      * 1 point: The problem is described but briefly or unclearly\n",
    "      * 2 points: The problem is well-described and it's clear what problem the project solves\n",
    "  * RAG flow\n",
    "      * 0 points: No knowledge base or LLM is used\n",
    "      * 1 point: No knowledge base is used, and the LLM is queried directly\n",
    "      * 2 points: Both a knowledge base and an LLM are used in the RAG flow \n",
    "  * Retrieval evaluation\n",
    "      * 0 points: No evaluation of retrieval is provided\n",
    "      * 1 point: Only one retrieval approach is evaluated\n",
    "      * 2 points: Multiple retrieval approaches are evaluated, and the best one is used\n",
    "  * RAG evaluation\n",
    "      * 0 points: No evaluation of RAG is provided\n",
    "      * 1 point: Only one RAG approach (e.g., one prompt) is evaluated\n",
    "      * 2 points: Multiple RAG approaches are evaluated, and the best one is used\n",
    "  * Interface\n",
    "     * 0 points: No way to interact with the application at all\n",
    "     * 1 point: Command line interface, a script, or a Jupyter notebook\n",
    "     * 2 points: UI (e.g., Streamlit), web application (e.g., Django), or an API (e.g., built with FastAPI) \n",
    "  * Ingestion pipeline\n",
    "     * 0 points: No ingestion\n",
    "     * 1 point: Semi-automated ingestion of the dataset into the knowledge base, e.g., with a Jupyter notebook\n",
    "     * 2 points: Automated ingestion with a Python script or a special tool (e.g., Mage, dlt, Airflow, Prefect)\n",
    "  * Monitoring\n",
    "     * 0 points: No monitoring\n",
    "     * 1 point: User feedback is collected OR there's a monitoring dashboard\n",
    "     * 2 points: User feedback is collected and there's a dashboard with at least 5 charts\n",
    "  * Containerization\n",
    "      * 0 points: No containerization\n",
    "      * 1 point: Dockerfile is provided for the main application OR there's a docker-compose for the dependencies only\n",
    "      * 2 points: Everything is in docker-compose\n",
    "  * Reproducibility\n",
    "      * 0 points: No instructions on how to run the code, the data is missing, or it's unclear how to access it\n",
    "      * 1 point: Some instructions are provided but are incomplete, OR instructions are clear and complete, the code works, but the data is missing\n",
    "      * 2 points: Instructions are clear, the dataset is accessible, it's easy to run the code, and it works. The versions for all dependencies are specified.\n",
    "  * Best practices\n",
    "      * [ ] Hybrid search: combining both text and vector search (at least evaluating it) (1 point)\n",
    "      * [ ] Document re-ranking (1 point)\n",
    "      * [ ] User query rewriting (1 point)\n",
    "  * Bonus points (not covered in the course)\n",
    "      * [ ] Deployment to the cloud (2 points)\n",
    "\n",
    "- Ok let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Initial Setup\n",
    "- Create a project in Github\n",
    "- Set up some local files you're going to need:\n",
    "  - Environment variable handling:\n",
    "    - Create .envrc and make sure it's in the .gitignore\n",
    "    - Create .envrc-template and don't put this in the .gitignore\n",
    "      - This file is for instructions on how to deploy your project if someone wanted to\n",
    "  - Pick the model you're going to use and create an API key\n",
    "    - In this case we'll probably just use ```gpt-4o-mini```\n",
    "    - "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
